{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "01_intro.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "56a6c96580974afdb8314a38c57d3a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "state": {
            "_view_name": "FileUploadView",
            "_counter": 1,
            "style": "IPY_MODEL_ca015e8016754de69c4d3a6ab17cea0a",
            "_dom_classes": [],
            "description": "Upload",
            "multiple": false,
            "_model_name": "FileUploadModel",
            "data": [
              null
            ],
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "accept": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "error": "",
            "description_tooltip": null,
            "metadata": [
              {
                "name": "cat.jpg",
                "type": "image/jpeg",
                "size": 41784,
                "lastModified": 1611059057684
              }
            ],
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17229edc8d634767aaefdeb8f6f7d850",
            "icon": "upload"
          }
        },
        "ca015e8016754de69c4d3a6ab17cea0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17229edc8d634767aaefdeb8f6f7d850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXd_dcO6JroN"
      },
      "source": [
        "# Ett Machine Learning exempel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIGHbrm7IQsJ"
      },
      "source": [
        "## Kommande studiecirkel\n",
        "Vi på Mejsla kommer att under våren anordna en studiecirkel där vi går igenom innehållet i boken [Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD](https://course.fast.ai/).\n",
        "\n",
        "Mer information om studiecirkeln hittas på [anmälningsformuläret](https://docs.google.com/forms/d/e/1FAIpQLSdMznAsCBbhE2s-5VWFgm9pecUM_jUB4VDltKixMfzIx5TfcA/viewform), som även kommer att mailas ut till alla deltagare efter mötet.\n",
        "\n",
        "I denna Notebook visar vi ett första exempel från boken, där vi tränar en model så att den kan markera om en bild innehåller en hund eller katt.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq99Ms9Pppy9"
      },
      "source": [
        "## Fastbook, fast.ai, PyTorch och TensorFlow\n",
        "Vi börjar med att installera det Python paket, [fastbook](https://pypi.org/project/fastbook/), som hör till boken. Det innehåller funktioner som används genom boken och gör det enkelt att komma igång med exempel.\n",
        "\n",
        "Boken är byggd på ramverket [fast.ai](https://www.fast.ai/) - något som kan ses via dess [requirements.txt](https://github.com/fastai/fastbook/blob/master/requirements.txt) fil som listar beroenden - vilket är ett ramverk för deep learning byggt ovanpå (gör det lättare att använda) [PyTorch](https://pytorch.org/), vilket är det framework som gör det tunga jobbet.\n",
        "\n",
        "PyTorch, främst utvecklat av Facebook's AI Research lab, är ett alternativ till [TensorFlow](https://www.tensorflow.org/), vilket är ett äldre och mer känt bibliotek för machine learning från Google - men underliggande begrepp och teori är överförbar mellan projekten.\n",
        "\n",
        "Som boken nämner händer mycket saker snabbt inom utveckling i allmänhet och Machine Learning i synnerhet. Vilka bibliotek och ramverk som kommer att användas kommer med stor sannolikhet ändras över tid, men underliggande förståelse för tekniker och begrepp kommer göra det lättare att anpassa sig till och använda till nya verktyg inom området.\n",
        "\n",
        "Setup-koden kommer att använda Google Drive, och kommer därför be om tillgång till denna:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngscN9OyVrxx"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "from fastbook import *\n",
        "setup_book()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULzEi4MsOmW6"
      },
      "source": [
        "## GPU och TPU\n",
        "En GPU (graphics processing unit) är en grafikprocessor, en mikroprocessor som sitter på en dators grafikkort. Den är mer specialiserad än generella CPU:s, med många fler kärnor som kan utföra mer specialiserade beräknar paralllelt, och som namnet antyder används dessa ursprungligen för att rendera datorgrafik - men samma arkitektur passar väl för att träna modeller inom Machine Learning.\n",
        "\n",
        "TPU:er (tensor processing units) är än mer specialiserad hårdvara för just Machine Learning. Från Wikipedia:\n",
        "\n",
        "> Compared to a graphics processing unit, it is designed for a high volume of low precision computation (e.g. as little as 8-bit precision) with more input/output operations per joule, and lacks hardware for rasterisation/texture mapping.\n",
        "\n",
        "[...]\n",
        "\n",
        "> Different types of processors are suited for different types of machine learning models, TPUs are well suited for CNNs while GPUs have benefits for some fully-connected neural networks, and CPUs can have advantages for RNNs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJY7yayFVrx5"
      },
      "source": [
        "## En första modell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUeNs9AhVrx7"
      },
      "source": [
        "Nedan följer en kodsnutt som trots dess korthet är ett fullständigt system för att skapa och träna en state-of-the-art modell för att känna igen katter eller hundar.\n",
        "\n",
        "Följande sker:\n",
        "\n",
        "1. En datamängd vid namn [Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/) som innehåller 7,349 bilder av katter och hundar från 37 raser kommer laddas ner från fast.ai:s samling av data till den GPU server som används.\n",
        "2. En *förtränad modell* (pretrained model) som redan har tränats på 1.3 miljoner bilder och konstaterats prestera väl, kommer att laddas ner. Namnet på modellen är `resnet34`.\n",
        "3. Den förtränade modellen kommer att anpassas (*fine-tuned*) användandes *transfer learning* för att skapa en modell som är specifikt anpassad för att känna igenom katter och hundar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfH1Pj_sVrx7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b41f60ef-8935-433c-a39e-8b40aa946331"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "\n",
        "def is_cat(x):\n",
        "  return x[0].isupper()\n",
        "\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))\n",
        "\n",
        "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.162983</td>\n",
              "      <td>0.025543</td>\n",
              "      <td>0.008796</td>\n",
              "      <td>00:54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.065430</td>\n",
              "      <td>0.026112</td>\n",
              "      <td>0.007442</td>\n",
              "      <td>00:58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONOL47xHmxXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaxGU06nVrx7"
      },
      "source": [
        "> OBS: Det kommer ta några minuter att ladda ner och anpassa modellen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWTqj_TGVrx8"
      },
      "source": [
        "# Bedöma modells effektivitet och testa det manuellt\n",
        "\n",
        "Hur ska vi bedöma hur bra modellen presterar?\n",
        "\n",
        "Sista kolumnen i tabellen visar error rate, den andel av bilderna som klassificerades inkorrekt.\n",
        "\n",
        "Som ses av siffran är modellen effektiv trots snabb tid för anpassning, och faktiskt bättre än vad någon skulle kunna prestera för säg 10 år sen.\n",
        "\n",
        "För att manuellt bekräfta att det fungerar, låt oss ladda upp en bild (använda google sökning efter hund eller katt bilder):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19IqhLWkVrx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "56a6c96580974afdb8314a38c57d3a22",
            "ca015e8016754de69c4d3a6ab17cea0a",
            "17229edc8d634767aaefdeb8f6f7d850"
          ]
        },
        "outputId": "ce3ff800-cd3e-483b-ed94-a1807880ed86"
      },
      "source": [
        "uploader = widgets.FileUpload()\n",
        "uploader"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56a6c96580974afdb8314a38c57d3a22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "FileUpload(value={}, description='Upload')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-X7WHyWVrx9"
      },
      "source": [
        "Efter att ha laddat upp en bild med Upload-knappen ovan kan vi använda modellen för att klassificera bilden:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNZRvPW_Vrx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "423c3a2b-7616-4693-800d-135ec5e42352"
      },
      "source": [
        "img = PILImage.create(uploader.data[0])\n",
        "is_cat,_,probs = learn.predict(img)\n",
        "print(f\"Is this a cat?: {is_cat}.\")\n",
        "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Is this a cat?: True.\n",
            "Probability it's a cat: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNmNCvBUVrx9"
      },
      "source": [
        "För att förklara vad vi gjort ska vi backa ut ett steg."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOAsArfznJB6"
      },
      "source": [
        "## Historik\n",
        "På 40-talet skapades en modell av neuroner i hjärnan.\n",
        "\n",
        "![Neuroner](https://github.com/fastai/fastbook/raw/fb570779062177662fbfde0f5dbb1e9f08dabbee/images/chapter7_neuron.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_DgvvJVrx9"
      },
      "source": [
        "## Vad är Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8XK5HYyVrx9"
      },
      "source": [
        "\n",
        "*Machine learning* är, likt vanlig programmering, ett sätt att få datorer at utföra ett önskat jobb. Med vanlig programmering menar vi modellen där vi exakt beskriver de steg ett program ska ta för att givet input producera ett visst output:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": false,
        "id": "8nRl1zFPVrx9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "c02db052-db56-495a-c3a2-c2ab668efa83"
      },
      "source": [
        "gv('''program[shape=box3d width=1 height=0.7]\n",
        "inputs->program->results''')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f26abef58d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"288pt\" height=\"58pt\"\n viewBox=\"0.00 0.00 288.49 58.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-54 284.4879,-54 284.4879,4 -4,4\"/>\n<!-- program -->\n<g id=\"node1\" class=\"node\">\n<title>program</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"175.594,-50 107.594,-50 103.594,-46 103.594,0 171.594,0 175.594,-4 175.594,-50\"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 103.594,-46 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 171.594,0 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 175.594,-50 \"/>\n<text text-anchor=\"middle\" x=\"139.594\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">program</text>\n</g>\n<!-- results -->\n<g id=\"node3\" class=\"node\">\n<title>results</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"246.0409\" cy=\"-25\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"246.0409\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n</g>\n<!-- program&#45;&gt;results -->\n<g id=\"edge2\" class=\"edge\">\n<title>program&#45;&gt;results</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M175.6321,-25C183.865,-25 192.7125,-25 201.2618,-25\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"201.4807,-28.5001 211.4807,-25 201.4806,-21.5001 201.4807,-28.5001\"/>\n</g>\n<!-- inputs -->\n<g id=\"node2\" class=\"node\">\n<title>inputs</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.797\" cy=\"-25\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"33.797\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n</g>\n<!-- inputs&#45;&gt;program -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs&#45;&gt;program</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M67.8542,-25C75.9278,-25 84.675,-25 93.1939,-25\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.4113,-28.5001 103.4113,-25 93.4112,-21.5001 93.4113,-28.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4EX5ItbVrx-"
      },
      "source": [
        "Men för att känna igen objekt i en bild är det svårt - vad är egentligen stegen våra hjärnor tar för att känna igen om en bild representerar en hund eller en katt? Hur skulle man översätta det till kod? Svaret är att det är svårt - det händer i våra hjärnor utan att vi är medvetna om exakta stegen.\n",
        "\n",
        "På 40-talet börjades det formuleras ett annat sätt för datorer att utföra uppgifter som kallades *machine learning*. I en klassisk skrift från 1962,  \"Artificial Intelligence: A Frontier of Automation\", skrevs det (fritt översatt):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZz-iSI8Vrx-"
      },
      "source": [
        "> Att programmera en dator för en sådan uppgift är en svår (om inte omöjlig) uppgift. Inte nödvändigtvis för att en inneboende komplexitet i problemet, utan för nödvändigheten att i detalj skriva ner varje steg. Datorer, som de flesta programmerare ser det, är enorma idioter, inte enorma hjärnor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aAkmjJIVrx-"
      },
      "source": [
        "Den grundläggande idén var att istället för att i detalj beskriva hur problemet ska lösas, så visar vi programmet exempel på problem att lösa, och låter det sedan självt koma på lösningar.\n",
        "\n",
        "Det här visade sig snabbt lovande i initiala experiment - ett program för damspel, checkers, blev statsmästaste i Connecticut 1961."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6mVcts7Vrx-"
      },
      "source": [
        "För att sammanfatta begrepp som användes:\n",
        "\n",
        "- Vikter (`weights`) är variabler som ges till modellen. Tillsammans med input-datat definierar de vilken output en viss modell ger.\n",
        "\n",
        "De kan ses som en form av input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "zGPJqLonVrx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "661229a1-bea6-4f38-d892-2144e8204611"
      },
      "source": [
        "gv('''model[shape=box3d width=1 height=0.7] inputs->model->results; weights->model''')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f26abdcc7f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"300pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 300.19 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 296.1869,-94 296.1869,4 -4,4\"/>\n<!-- model -->\n<g id=\"node1\" class=\"node\">\n<title>model</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"187.293,-70 119.293,-70 115.293,-66 115.293,-20 183.293,-20 187.293,-24 187.293,-70\"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"183.293,-66 115.293,-66 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"183.293,-66 183.293,-20 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"183.293,-66 187.293,-70 \"/>\n<text text-anchor=\"middle\" x=\"151.293\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model</text>\n</g>\n<!-- results -->\n<g id=\"node3\" class=\"node\">\n<title>results</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"257.7399\" cy=\"-45\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"257.7399\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n</g>\n<!-- model&#45;&gt;results -->\n<g id=\"edge2\" class=\"edge\">\n<title>model&#45;&gt;results</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187.331,-45C195.564,-45 204.4115,-45 212.9607,-45\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.1797,-48.5001 223.1796,-45 213.1796,-41.5001 213.1797,-48.5001\"/>\n</g>\n<!-- inputs -->\n<g id=\"node2\" class=\"node\">\n<title>inputs</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"39.6465\" cy=\"-72\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"39.6465\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n</g>\n<!-- inputs&#45;&gt;model -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M70.4499,-64.5507C81.133,-61.9671 93.3575,-59.0108 105.0104,-56.1927\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.1535,-59.5173 115.0506,-53.7647 104.508,-52.7134 106.1535,-59.5173\"/>\n</g>\n<!-- weights -->\n<g id=\"node4\" class=\"node\">\n<title>weights</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"39.6465\" cy=\"-18\" rx=\"39.7935\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"39.6465\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">weights</text>\n</g>\n<!-- weights&#45;&gt;model -->\n<g id=\"edge3\" class=\"edge\">\n<title>weights&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M74.6658,-26.4689C84.3542,-28.8119 95.0182,-31.3908 105.2321,-33.8609\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.7007,-37.3332 115.2433,-36.2819 106.3462,-30.5293 104.7007,-37.3332\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVw9yGAIVrx-"
      },
      "source": [
        "Vi har här också ändrat namnet från *program* till *model*, vilket är modernare namngivning och visar att det rör sig om en speciell typ av program skiljt från traditionella datorprogram.\n",
        "\n",
        "En *model* är ett specill typ av program som kan göra *olika saker* beroende på de *weights* som anges.\n",
        "\n",
        "- I dam-spelet kan olika vikter vara olika strategier.\n",
        "- I våran hund&katt igenkännare är vikter det som erhållts från vår anpassning av en generell bild-klassifierare till att just känna igen katter och hundar.\n",
        "\n",
        "För att en model ska kunna lära sig behövs dessutom ett *automatiskt sätt att testa effektiviteten hos en viss uppsättning vikter*.\n",
        "\n",
        "- I fallet med damspelet är effektiviteten hur väl modellen spelade, och ett automatiskt sätt att testa detta skulle kunna vara att låta två modeller spela med varandra.\n",
        "- I våran hund&katt igenkännare så använda vi oss av ett *facit* - någon har redan tagit sig tid att manuellt markera vilka bilder som avbildade katter och vilka som avbildade hundar, och markerat detta genom att låta filnamnet börja med stor bokstav eller inte.\n",
        "\n",
        "Slutligen så behövs en *mekanism för att uppdatera vikterna för att maximera effektiviteten*. Detaljerna här är icke triviala, men vi skulle kunna tänka oss att vi tittar på skillnader mellan en vinnande modell och en som förlorar, och ändra vikterna en bit åt det håll som vinnande modellen är i.\n",
        "\n",
        "\n",
        "Nedan visas en fullständig modell av det vi gått igenom:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "5-ps9eutVrx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "9cb1c115-1cc8-49b5-8eeb-1dc7dc438eb0"
      },
      "source": [
        "gv('''ordering=in model[shape=box3d width=1 height=0.7] inputs->model->results; weights->model; results->performance performance->weights[constraint=false label=update]''')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f26abdcc0f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"492pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 491.58 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 487.5767,-94 487.5767,4 -4,4\"/>\n<!-- model -->\n<g id=\"node1\" class=\"node\">\n<title>model</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"188.293,-77 120.293,-77 116.293,-73 116.293,-27 184.293,-27 188.293,-31 188.293,-77\"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"184.293,-73 116.293,-73 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"184.293,-73 184.293,-27 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"184.293,-73 188.293,-77 \"/>\n<text text-anchor=\"middle\" x=\"152.293\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model</text>\n</g>\n<!-- results -->\n<g id=\"node3\" class=\"node\">\n<title>results</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"297.7399\" cy=\"-52\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"297.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n</g>\n<!-- model&#45;&gt;results -->\n<g id=\"edge2\" class=\"edge\">\n<title>model&#45;&gt;results</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M188.6202,-52C208.0549,-52 232.162,-52 252.7707,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"252.8772,-55.5001 262.8772,-52 252.8771,-48.5001 252.8772,-55.5001\"/>\n</g>\n<!-- inputs -->\n<g id=\"node2\" class=\"node\">\n<title>inputs</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"39.6465\" cy=\"-72\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"39.6465\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n</g>\n<!-- inputs&#45;&gt;model -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M71.9264,-66.2688C82.5866,-64.3761 94.6614,-62.2323 106.1514,-60.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.8137,-63.6295 116.0478,-58.4352 105.5899,-56.7373 106.8137,-63.6295\"/>\n</g>\n<!-- performance -->\n<g id=\"node5\" class=\"node\">\n<title>performance</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"426.3818\" cy=\"-52\" rx=\"57.3905\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"426.3818\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">performance</text>\n</g>\n<!-- results&#45;&gt;performance -->\n<g id=\"edge4\" class=\"edge\">\n<title>results&#45;&gt;performance</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M332.2136,-52C340.5212,-52 349.6824,-52 358.93,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.9624,-55.5001 368.9624,-52 358.9624,-48.5001 358.9624,-55.5001\"/>\n</g>\n<!-- weights -->\n<g id=\"node4\" class=\"node\">\n<title>weights</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"39.6465\" cy=\"-18\" rx=\"39.7935\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"39.6465\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">weights</text>\n</g>\n<!-- weights&#45;&gt;model -->\n<g id=\"edge3\" class=\"edge\">\n<title>weights&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72.8349,-28.0172C83.3758,-31.1988 95.2252,-34.7753 106.4921,-38.1759\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"105.611,-41.5659 116.1958,-41.1048 107.6337,-34.8645 105.611,-41.5659\"/>\n</g>\n<!-- performance&#45;&gt;weights -->\n<g id=\"edge5\" class=\"edge\">\n<title>performance&#45;&gt;weights</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M387.4301,-38.6502C370.6367,-33.4674 350.6491,-28.053 332.1869,-25 247.7864,-11.0431 147.8468,-12.4185 89.3275,-14.9945\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.0716,-11.5026 79.247,-15.4684 89.4004,-18.4948 89.0716,-11.5026\"/>\n<text text-anchor=\"middle\" x=\"225.793\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">update</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJomJ4znVrx_"
      },
      "source": [
        "Lägg märke till skillnaden mellan modellens *resultat* (t.ex. de drag som sker i Dam-spelet) och dess *effektivitet* (t.ex. om det vinner ett spel, och isf hur snabbt).\n",
        "\n",
        "När modellen väl har blivit tränad - dvs, när vi har bestämt oss för slutliga vikter, så kan vi se vikterna som del av modellen, och användandet av den därefter blir som visas nedan:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "VReVEn0PVrx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6e5034e5-b266-4862-b7b3-fe5ac22bda12"
      },
      "source": [
        "gv('''model[shape=box3d width=1 height=0.7] inputs->model->results''')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f26abdcc278>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"288pt\" height=\"58pt\"\n viewBox=\"0.00 0.00 288.49 58.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-54 284.4879,-54 284.4879,4 -4,4\"/>\n<!-- model -->\n<g id=\"node1\" class=\"node\">\n<title>model</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"175.594,-50 107.594,-50 103.594,-46 103.594,0 171.594,0 175.594,-4 175.594,-50\"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 103.594,-46 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 171.594,0 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"171.594,-46 175.594,-50 \"/>\n<text text-anchor=\"middle\" x=\"139.594\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model</text>\n</g>\n<!-- results -->\n<g id=\"node3\" class=\"node\">\n<title>results</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"246.0409\" cy=\"-25\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"246.0409\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">results</text>\n</g>\n<!-- model&#45;&gt;results -->\n<g id=\"edge2\" class=\"edge\">\n<title>model&#45;&gt;results</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M175.6321,-25C183.865,-25 192.7125,-25 201.2618,-25\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"201.4807,-28.5001 211.4807,-25 201.4806,-21.5001 201.4807,-28.5001\"/>\n</g>\n<!-- inputs -->\n<g id=\"node2\" class=\"node\">\n<title>inputs</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.797\" cy=\"-25\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"33.797\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n</g>\n<!-- inputs&#45;&gt;model -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M67.8542,-25C75.9278,-25 84.675,-25 93.1939,-25\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.4113,-28.5001 103.4113,-25 93.4112,-21.5001 93.4113,-28.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22t5WRv-xENg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjd1LeoPVrx_"
      },
      "source": [
        "Om vi jämför med den initiala modellen för ett traditionellt datorprogram ser vi att den ser likadan ut, med *program* utbytt mot *model*. Det är en trevlig egenskap:\n",
        "- När väl modellen är tränad kan den användas som ett traditionellt program, utan att vara krångligare för den som anropar det.\n",
        "\n",
        "För att sammanfatta definitionen:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVxUS_BNVrx_"
      },
      "source": [
        "> Machine Learning: The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFcWV3DXVrx_"
      },
      "source": [
        "### What Is a Neural Network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILCpdlBQVrx_"
      },
      "source": [
        "It's not too hard to imagine what the model might look like for a checkers program. There might be a range of checkers strategies encoded, and some kind of search mechanism, and then the weights could vary how strategies are selected, what parts of the board are focused on during a search, and so forth. But it's not at all obvious what the model might look like for an image recognition program, or for understanding text, or for many other interesting problems we might imagine.\n",
        "\n",
        "What we would like is some kind of function that is so flexible that it could be used to solve any given problem, just by varying its weights. Amazingly enough, this function actually exists! It's the neural network, which we already discussed. That is, if you regard a neural network as a mathematical function, it turns out to be a function which is extremely flexible depending on its weights. A mathematical proof called the *universal approximation theorem* shows that this function can solve any problem to any level of accuracy, in theory. The fact that neural networks are so flexible means that, in practice, they are often a suitable kind of model, and you can focus your effort on the process of training them—that is, of finding good weight assignments.\n",
        "\n",
        "But what about that process?  One could imagine that you might need to find a new \"mechanism\" for automatically updating weights for every problem. This would be laborious. What we'd like here as well is a completely general way to update the weights of a neural network, to make it improve at any given task. Conveniently, this also exists!\n",
        "\n",
        "This is called *stochastic gradient descent* (SGD). We'll see how neural networks and SGD work in detail in <<chapter_mnist_basics>>, as well as explaining the universal approximation theorem. For now, however, we will instead use Samuel's own words: *We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV8BGnC6VryA"
      },
      "source": [
        "> J: Don't worry, neither SGD nor neural nets are mathematically complex. Both nearly entirely rely on addition and multiplication to do their work (but they do a _lot_ of addition and multiplication!). The main reaction we hear from students when they see the details is: \"Is that all it is?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-K8MalaVryA"
      },
      "source": [
        "In other words, to recap, a neural network is a particular kind of machine learning model, which fits right in to Samuel's original conception. Neural networks are special because they are highly flexible, which means they can solve an unusually wide range of problems just by finding the right weights. This is powerful, because stochastic gradient descent provides us a way to find those weight values automatically.\n",
        "\n",
        "Having zoomed out, let's now zoom back in and revisit our image classification problem using Samuel's framework.\n",
        "\n",
        "Our inputs are the images. Our weights are the weights in the neural net. Our model is a neural net. Our results are the values that are calculated by the neural net, like \"dog\" or \"cat.\"\n",
        "\n",
        "What about the next piece, an *automatic means of testing the effectiveness of any current weight assignment in terms of actual performance*? Determining \"actual performance\" is easy enough: we can simply define our model's performance as its accuracy at predicting the correct answers.\n",
        "\n",
        "Putting this all together, and assuming that SGD is our mechanism for updating the weight assignments, we can see how our image classifier is a machine learning model, much like Samuel envisioned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8amNVFBaVryA"
      },
      "source": [
        "### A Bit of Deep Learning Jargon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6tsKa3dVryA"
      },
      "source": [
        "Samuel was working in the 1960s, and since then terminology has changed. Here is the modern deep learning terminology for all the pieces we have discussed:\n",
        "\n",
        "- The functional form of the *model* is called its *architecture* (but be careful—sometimes people use *model* as a synonym of *architecture*, so this can get confusing).\n",
        "- The *weights* are called *parameters*.\n",
        "- The *predictions* are calculated from the *independent variable*, which is the *data* not including the *labels*.\n",
        "- The *results* of the model are called *predictions*.\n",
        "- The measure of *performance* is called the *loss*.\n",
        "- The loss depends not only on the predictions, but also the correct *labels* (also known as *targets* or the *dependent variable*); e.g., \"dog\" or \"cat.\"\n",
        "\n",
        "After making these changes, our diagram in <<training_loop>> looks like <<detailed_loop>>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": true,
        "id": "TOStJxckVryA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "63d719e9-dcb2-4ed0-dad4-9dd9b8d0462d"
      },
      "source": [
        "#hide_input\n",
        "#caption Detailed training loop\n",
        "#id detailed_loop\n",
        "gv('''ordering=in\n",
        "model[shape=box3d width=1 height=0.7 label=architecture]\n",
        "inputs->model->predictions; parameters->model; labels->loss; predictions->loss\n",
        "loss->parameters[constraint=false label=update]''')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f26abe180b8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"497pt\" height=\"135pt\"\n viewBox=\"0.00 0.00 497.08 134.71\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 130.7121)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-130.7121 493.0819,-130.7121 493.0819,4 -4,4\"/>\n<!-- model -->\n<g id=\"node1\" class=\"node\">\n<title>model</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"219.0911,-79.7121 141.0911,-79.7121 137.0911,-75.7121 137.0911,-29.7121 215.0911,-29.7121 219.0911,-33.7121 219.0911,-79.7121\"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"215.0911,-75.7121 137.0911,-75.7121 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"215.0911,-75.7121 215.0911,-29.7121 \"/>\n<polyline fill=\"none\" stroke=\"#000000\" points=\"215.0911,-75.7121 219.0911,-79.7121 \"/>\n<text text-anchor=\"middle\" x=\"178.0911\" y=\"-51.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">architecture</text>\n</g>\n<!-- predictions -->\n<g id=\"node3\" class=\"node\">\n<title>predictions</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"346.0865\" cy=\"-54.7121\" rx=\"51.9908\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"346.0865\" y=\"-51.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predictions</text>\n</g>\n<!-- model&#45;&gt;predictions -->\n<g id=\"edge2\" class=\"edge\">\n<title>model&#45;&gt;predictions</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.1874,-54.7121C238.6424,-54.7121 262.2946,-54.7121 283.8833,-54.7121\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"283.9603,-58.2122 293.9603,-54.7121 283.9602,-51.2122 283.9603,-58.2122\"/>\n</g>\n<!-- inputs -->\n<g id=\"node2\" class=\"node\">\n<title>inputs</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"50.0456\" cy=\"-74.7121\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"50.0456\" y=\"-71.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">inputs</text>\n</g>\n<!-- inputs&#45;&gt;model -->\n<g id=\"edge1\" class=\"edge\">\n<title>inputs&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M82.6882,-69.6135C96.0531,-67.5259 111.8418,-65.0598 126.6879,-62.741\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.4339,-66.167 136.7739,-61.1656 126.3535,-59.2508 127.4339,-66.167\"/>\n</g>\n<!-- loss -->\n<g id=\"node6\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"462.0819\" cy=\"-83.7121\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"462.0819\" y=\"-80.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predictions&#45;&gt;loss -->\n<g id=\"edge5\" class=\"edge\">\n<title>predictions&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M388.2916,-65.2638C400.9434,-68.4268 414.6806,-71.8613 426.8339,-74.8997\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"426.0613,-78.3142 436.6116,-77.3442 427.7592,-71.5232 426.0613,-78.3142\"/>\n</g>\n<!-- parameters -->\n<g id=\"node4\" class=\"node\">\n<title>parameters</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"50.0456\" cy=\"-20.7121\" rx=\"50.0912\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"50.0456\" y=\"-17.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">parameters</text>\n</g>\n<!-- parameters&#45;&gt;model -->\n<g id=\"edge3\" class=\"edge\">\n<title>parameters&#45;&gt;model</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M90.56,-31.4699C102.1226,-34.5401 114.8732,-37.9258 126.981,-41.1408\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3968,-44.6069 136.9601,-43.7905 128.1933,-37.8413 126.3968,-44.6069\"/>\n</g>\n<!-- labels -->\n<g id=\"node5\" class=\"node\">\n<title>labels</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"346.0865\" cy=\"-108.7121\" rx=\"31.6951\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"346.0865\" y=\"-105.0121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">labels</text>\n</g>\n<!-- labels&#45;&gt;loss -->\n<g id=\"edge4\" class=\"edge\">\n<title>labels&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M375.9582,-102.2739C391.2661,-98.9747 410.0232,-94.932 426.1201,-91.4627\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"427.2129,-94.8077 436.251,-89.2793 425.738,-87.9648 427.2129,-94.8077\"/>\n</g>\n<!-- loss&#45;&gt;parameters -->\n<g id=\"edge6\" class=\"edge\">\n<title>loss&#45;&gt;parameters</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M449.2992,-67.6054C437.5844,-54.1999 418.9311,-36.0143 398.0819,-27.7121 300.2825,11.2323 174.4458,.4215 104.0015,-10.4665\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3394,-7.0279 94.02,-12.0676 104.4481,-13.9396 103.3394,-7.0279\"/>\n<text text-anchor=\"middle\" x=\"256.5911\" y=\"-6.5121\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">update</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOlve5QdVryB"
      },
      "source": [
        "### Limitations Inherent To Machine Learning\n",
        "\n",
        "From this picture we can now see some fundamental things about training a deep learning model:\n",
        "\n",
        "- A model cannot be created without data.\n",
        "- A model can only learn to operate on the patterns seen in the input data used to train it.\n",
        "- This learning approach only creates *predictions*, not recommended *actions*.\n",
        "- It's not enough to just have examples of input data; we need *labels* for that data too (e.g., pictures of dogs and cats aren't enough to train a model; we need a label for each one, saying which ones are dogs, and which are cats).\n",
        "\n",
        "Generally speaking, we've seen that most organizations that say they don't have enough data, actually mean they don't have enough *labeled* data. If any organization is interested in doing something in practice with a model, then presumably they have some inputs they plan to run their model against. And presumably they've been doing that some other way for a while (e.g., manually, or with some heuristic program), so they have data from those processes! For instance, a radiology practice will almost certainly have an archive of medical scans (since they need to be able to check how their patients are progressing over time), but those scans may not have structured labels containing a list of diagnoses or interventions (since radiologists generally create free-text natural language reports, not structured data). We'll be discussing labeling approaches a lot in this book, because it's such an important issue in practice.\n",
        "\n",
        "Since these kinds of machine learning models can only make *predictions* (i.e., attempt to replicate labels), this can result in a significant gap between organizational goals and model capabilities. For instance, in this book you'll learn how to create a *recommendation system* that can predict what products a user might purchase. This is often used in e-commerce, such as to customize products shown on a home page by showing the highest-ranked items. But such a model is generally created by looking at a user and their buying history (*inputs*) and what they went on to buy or look at (*labels*), which means that the model is likely to tell you about products the user already has or already knows about, rather than new products that they are most likely to be interested in hearing about. That's very different to what, say, an expert at your local bookseller might do, where they ask questions to figure out your taste, and then tell you about authors or series that you've never heard of before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_JGgYVHVryB"
      },
      "source": [
        "Another critical insight comes from considering how a model interacts with its environment. This can create *feedback loops*, as described here:\n",
        "\n",
        "- A *predictive policing* model is created based on where arrests have been made in the past. In practice, this is not actually predicting crime, but rather predicting arrests, and is therefore partially simply reflecting biases in existing policing processes.\n",
        "- Law enforcement officers then might use that model to decide where to focus their police activity, resulting in increased arrests in those areas.\n",
        "- Data on these additional arrests would then be fed back in to retrain future versions of the model.\n",
        "\n",
        "This is a *positive feedback loop*, where the more the model is used, the more biased the data becomes, making the model even more biased, and so forth.\n",
        "\n",
        "Feedback loops can also create problems in commercial settings. For instance, a video recommendation system might be biased toward recommending content consumed by the biggest watchers of video (e.g., conspiracy theorists and extremists tend to watch more online video content than the average), resulting in those users increasing their video consumption, resulting in more of those kinds of videos being recommended. We'll consider this topic more in detail in <<chapter_ethics>>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ3rqWUcVryB"
      },
      "source": [
        "Now that you have seen the base of the theory, let's go back to our code example and see in detail how the code corresponds to the process we just described."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIup8AkZVryB"
      },
      "source": [
        "### How Our Image Recognizer Works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfEG7AoKVryB"
      },
      "source": [
        "Let's see just how our image recognizer code maps to these ideas. We'll put each line into a separate cell, and look at what each one is doing (we won't explain every detail of every parameter yet, but will give a description of the important bits; full details will come later in the book)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM1AWTANVryB"
      },
      "source": [
        "The first line imports all of the fastai.vision library.\n",
        "\n",
        "```python\n",
        "from fastai.vision.all import *\n",
        "```\n",
        "\n",
        "This gives us all of the functions and classes we will need to create a wide variety of computer vision models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hc4I_88VryB"
      },
      "source": [
        "> J: A lot of Python coders recommend avoiding importing a whole library like this (using the `import *` syntax), because in large software projects it can cause problems. However, for interactive work such as in a Jupyter notebook, it works great. The fastai library is specially designed to support this kind of interactive use, and it will only import the necessary pieces into your environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiuEsI3lVryB"
      },
      "source": [
        "The second line downloads a standard dataset from the [fast.ai datasets collection](https://course.fast.ai/datasets) (if not previously downloaded) to your server, extracts it (if not previously extracted), and returns a `Path` object with the extracted location:\n",
        "\n",
        "```python\n",
        "path = untar_data(URLs.PETS)/'images'\n",
        "```\n",
        "\n",
        "> S: Throughout my time studying at fast.ai, and even still today, I've learned a lot about productive coding practices. The fastai library and fast.ai notebooks are full of great little tips that have helped make me a better programmer. For instance, notice that the fastai library doesn't just return a string containing the path to the dataset, but a `Path` object. This is a really useful class from the Python 3 standard library that makes accessing files and directories much easier. If you haven't come across it before, be sure to check out its documentation or a tutorial and try it out. Note that the https://book.fast.ai[website] contains links to recommended tutorials for each chapter. I'll keep letting you know about little coding tips I've found useful as we come across them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGtt_GtVryB"
      },
      "source": [
        "In the third line we define a function, `is_cat`, labels cats based on a filename rule provided by the dataset creators:\n",
        "```python\n",
        "def is_cat(x): return x[0].isupper()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH_w2m63VryB"
      },
      "source": [
        "We use that function in the fourth line, which tells fastai what kind of dataset we have, and how it is structured:\n",
        "\n",
        "```python\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))\n",
        "```\n",
        "\n",
        "There are various different classes for different kinds of deep learning datasets and problems—here we're using `ImageDataLoaders`. The first part of the class name will generally be the type of data you have, such as image, or text.\n",
        "\n",
        "The other important piece of information that we have to tell fastai is how to get the labels from the dataset. Computer vision datasets are normally structured in such a way that the label for an image is part of the filename, or path—most commonly the parent folder name. fastai comes with a number of standardized labeling methods, and ways to write your own. Here we're telling fastai to use the `is_cat` function we just defined.\n",
        "\n",
        "Finally, we define the `Transform`s that we need. A `Transform` contains code that is applied automatically during training; fastai includes many predefined `Transform`s, and adding new ones is as simple as creating a Python function. There are two kinds: `item_tfms` are applied to each item (in this case, each item is resized to a 224-pixel square), while `batch_tfms` are applied to a *batch* of items at a time using the GPU, so they're particularly fast (we'll see many examples of these throughout this book).\n",
        "\n",
        "Why 224 pixels? This is the standard size for historical reasons (old pretrained models require this size exactly), but you can pass pretty much anything. If you increase the size, you'll often get a model with better results (since it will be able to focus on more details), but at the price of speed and memory consumption; the opposite is true if you decrease the size. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OXfzzIVryC"
      },
      "source": [
        "> Note: Classification and Regression: _classification_ and _regression_ have very specific meanings in machine learning. These are the two main types of model that we will be investigating in this book. A classification model is one which attempts to predict a class, or category. That is, it's predicting from a number of discrete possibilities, such as \"dog\" or \"cat.\" A regression model is one which attempts to predict one or more numeric quantities, such as a temperature or a location. Sometimes people use the word _regression_ to refer to a particular kind of model called a _linear regression model_; this is a bad practice, and we won't be using that terminology in this book!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBI-xk6CVryC"
      },
      "source": [
        "The Pet dataset contains 7,390 pictures of dogs and cats, consisting of 37 different breeds. Each image is labeled using its filename: for instance the file *great\\_pyrenees\\_173.jpg* is the 173rd example of an image of a Great Pyrenees breed dog in the dataset. The filenames start with an uppercase letter if the image is a cat, and a lowercase letter otherwise. We have to tell fastai how to get labels from the filenames, which we do by calling `from_name_func` (which means that labels can be extracted using a function applied to the filename), and passing `x[0].isupper()`, which evaluates to `True` if the first letter is uppercase (i.e., it's a cat).\n",
        "\n",
        "The most important parameter to mention here is `valid_pct=0.2`. This tells fastai to hold out 20% of the data and *not use it for training the model at all*. This 20% of the data is called the *validation set*; the remaining 80% is called the *training set*. The validation set is used to measure the accuracy of the model. By default, the 20% that is held out is selected randomly. The parameter `seed=42` sets the *random seed* to the same value every time we run this code, which means we get the same validation set every time we run it—this way, if we change our model and retrain it, we know that any differences are due to the changes to the model, not due to having a different random validation set.\n",
        "\n",
        "fastai will *always* show you your model's accuracy using *only* the validation set, *never* the training set. This is absolutely critical, because if you train a large enough model for a long enough time, it will eventually memorize the label of every item in your dataset! The result will not actually be a useful model, because what we care about is how well our model works on *previously unseen images*. That is always our goal when creating a model: for it to be useful on data that the model only sees in the future, after it has been trained.\n",
        "\n",
        "Even when your model has not fully memorized all your data, earlier on in training it may have memorized certain parts of it. As a result, the longer you train for, the better your accuracy will get on the training set; the validation set accuracy will also improve for a while, but eventually it will start getting worse as the model starts to memorize the training set, rather than finding generalizable underlying patterns in the data. When this happens, we say that the model is *overfitting*.\n",
        "\n",
        "<<img_overfit>> shows what happens when you overfit, using a simplified example where we have just one parameter, and some randomly generated data based on the function `x**2`. As you can see, although the predictions in the overfit model are accurate for data near the observed data points, they are way off when outside of that range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgk3pZW-VryC"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/att_00000.png?raw=1\" alt=\"Example of overfitting\" caption=\"Example of overfitting\" id=\"img_overfit\" width=\"700\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN_kcs3QVryC"
      },
      "source": [
        "**Overfitting is the single most important and challenging issue** when training for all machine learning practitioners, and all algorithms. As you will see, it is very easy to create a model that does a great job at making predictions on the exact data it has been trained on, but it is much harder to make accurate predictions on data the model has never seen before. And of course, this is the data that will actually matter in practice. For instance, if you create a handwritten digit classifier (as we will very soon!) and use it to recognize numbers written on checks, then you are never going to see any of the numbers that the model was trained on—check will have slightly different variations of writing to deal with. You will learn many methods to avoid overfitting in this book. However, you should only use those methods after you have confirmed that overfitting is actually occurring (i.e., you have actually observed the validation accuracy getting worse during training). We often see practitioners using over-fitting avoidance techniques even when they have enough data that they didn't need to do so, ending up with a model that may be less accurate than what they could have achieved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C6_FywfVryC"
      },
      "source": [
        "> important: Validation Set: When you train a model, you must _always_ have both a training set and a validation set, and must measure the accuracy of your model only on the validation set. If you train for too long, with not enough data, you will see the accuracy of your model start to get worse; this is called _overfitting_. fastai defaults `valid_pct` to `0.2`, so even if you forget, fastai will create a validation set for you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLiGgkWFVryC"
      },
      "source": [
        "The fifth line of the code training our image recognizer tells fastai to create a *convolutional neural network* (CNN) and specifies what *architecture* to use (i.e. what kind of model to create), what data we want to train it on, and what *metric* to use:\n",
        "\n",
        "```python\n",
        "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
        "```\n",
        "\n",
        "Why a CNN? It's the current state-of-the-art approach to creating computer vision models. We'll be learning all about how CNNs work in this book. Their structure is inspired by how the human vision system works.\n",
        "\n",
        "There are many different architectures in fastai, which we will introduce in this book (as well as discussing how to create your own). Most of the time, however, picking an architecture isn't a very important part of the deep learning process. It's something that academics love to talk about, but in practice it is unlikely to be something you need to spend much time on. There are some standard architectures that work most of the time, and in this case we're using one called _ResNet_ that we'll be talking a lot about during the book; it is both fast and accurate for many datasets and problems. The `34` in `resnet34` refers to the number of layers in this variant of the architecture (other options are `18`, `50`, `101`, and `152`). Models using architectures with more layers take longer to train, and are more prone to overfitting (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse). On the other hand, when using more data, they can be quite a bit more accurate.\n",
        "\n",
        "What is a metric? A *metric* is a function that measures the quality of the model's predictions using the validation set, and will be printed at the end of each *epoch*. In this case, we're using `error_rate`, which is a function provided by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is `accuracy` (which is just `1.0 - error_rate`). fastai provides many more, which will be discussed throughout this book.\n",
        "\n",
        "The concept of a metric may remind you of *loss*, but there is an important distinction. The entire purpose of loss is to define a \"measure of performance\" that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbEUOKF0VryC"
      },
      "source": [
        "`cnn_learner` also has a parameter `pretrained`, which defaults to `True` (so it's used in this case, even though we haven't specified it), which sets the weights in your model to values that have already been trained by experts to recognize a thousand different categories across 1.3 million photos (using the famous [*ImageNet* dataset](http://www.image-net.org/)). A model that has weights that have already been trained on some other dataset is called a *pretrained model*. You should nearly always use a pretrained model, because it means that your model, before you've even shown it any of your data, is already very capable. And, as you'll see, in a deep learning model many of these capabilities are things you'll need, almost regardless of the details of your project. For instance, parts of pretrained models will handle edge, gradient, and color detection, which are needed for many tasks.\n",
        "\n",
        "When using a pretrained model, `cnn_learner` will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the *head*.\n",
        "\n",
        "Using pretrained models is the *most* important method we have to allow us to train more accurate models, more quickly, with less data, and less time and money. You might think that would mean that using pretrained models would be the most studied area in academic deep learning... but you'd be very, very wrong! The importance of pretrained models is generally not recognized or discussed in most courses, books, or software library features, and is rarely considered in academic papers. As we write this at the start of 2020, things are just starting to change, but it's likely to take a while. So be careful: most people you speak to will probably greatly underestimate what you can do in deep learning with few resources, because they probably won't deeply understand how to use pretrained models.\n",
        "\n",
        "Using a pretrained model for a task different to what it was originally trained for is known as *transfer learning*. Unfortunately, because transfer learning is so under-studied, few domains have pretrained models available. For instance, there are currently few pretrained models available in medicine, making transfer learning challenging to use in that domain. In addition, it is not yet well understood how to use transfer learning for tasks such as time series analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh81UjCJVryC"
      },
      "source": [
        "> jargon: Transfer learning: Using a pretrained model for a task different to what it was originally trained for."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv3Ul3EVVryD"
      },
      "source": [
        "The sixth line of our code tells fastai how to *fit* the model:\n",
        "\n",
        "```python\n",
        "learn.fine_tune(1)\n",
        "```\n",
        "\n",
        "As we've discussed, the architecture only describes a *template* for a mathematical function; it doesn't actually do anything until we provide values for the millions of parameters it contains.\n",
        "\n",
        "This is the key to deep learning—determining how to fit the parameters of a model to get it to solve your problem. In order to fit a model, we have to provide at least one piece of information: how many times to look at each image (known as number of *epochs*). The number of epochs you select will largely depend on how much time you have available, and how long you find it takes in practice to fit your model. If you select a number that is too small, you can always train for more epochs later.\n",
        "\n",
        "But why is the method called `fine_tune`, and not `fit`? fastai actually *does* have a method called `fit`, which does indeed fit a model (i.e. look at images in the training set multiple times, each time updating the parameters to make the predictions closer and closer to the target labels). But in this case, we've started with a pretrained model, and we don't want to throw away all those capabilities that it already has. As you'll learn in this book, there are some important tricks to adapt a pretrained model for a new dataset—a process called *fine-tuning*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YR-LdUwVryD"
      },
      "source": [
        "> jargon: Fine-tuning: A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhQIyDJLVryD"
      },
      "source": [
        "When you use the `fine_tune` method, fastai will use these tricks for you. There are a few parameters you can set (which we'll discuss later), but in the default form shown here, it does two steps:\n",
        "\n",
        "1. Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with your dataset.\n",
        "1. Use the number of epochs requested when calling the method to fit the entire model, updating the weights of the later layers (especially the head) faster than the earlier layers (which, as we'll see, generally don't require many changes from the pretrained weights).\n",
        "\n",
        "The *head* of a model is the part that is newly added to be specific to the new dataset. An *epoch* is one complete pass through the dataset. After calling `fit`, the results after each epoch are printed, showing the epoch number, the training and validation set losses (the \"measure of performance\" used for training the model), and any *metrics* you've requested (error rate, in this case)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB_f1pSxVryD"
      },
      "source": [
        "So, with all this code our model learned to recognize cats and dogs just from labeled examples. But how did it do it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu25QZ1EVryD"
      },
      "source": [
        "### What Our Image Recognizer Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10GUzTvBVryJ"
      },
      "source": [
        "## Validation Sets and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpKbBjWuVryK"
      },
      "source": [
        "As we've discussed, the goal of a model is to make predictions about data. But the model training process is fundamentally dumb. If we trained a model with all our data, and then evaluated the model using that same data, we would not be able to tell how well our model can perform on data it hasn’t seen. Without this very valuable piece of information to guide us in training our model, there is a very good chance it would become good at making predictions about that data but would perform poorly on new data.\n",
        "\n",
        "To avoid this, our first step was to split our dataset into two sets: the *training set* (which our model sees in training) and the *validation set*, also known as the *development set* (which is used only for evaluation). This lets us test that the model learns lessons from the training data that generalize to new data, the validation data.\n",
        "\n",
        "One way to understand this situation is that, in a sense, we don't want our model to get good results by \"cheating.\" If it makes an accurate prediction for a data item, that should be because it has learned characteristics of that kind of item, and not because the model has been shaped by *actually having seen that particular item*.\n",
        "\n",
        "Splitting off our validation data means our model never sees it in training and so is completely untainted by it, and is not cheating in any way. Right?\n",
        "\n",
        "In fact, not necessarily. The situation is more subtle. This is because in realistic scenarios we rarely build a model just by training its weight parameters once. Instead, we are likely to explore many versions of a model through various modeling choices regarding network architecture, learning rates, data augmentation strategies, and other factors we will discuss in upcoming chapters. Many of these choices can be described as choices of *hyperparameters*. The word reflects that they are parameters about parameters, since they are the higher-level choices that govern the meaning of the weight parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5kU2BJFVryK"
      },
      "source": [
        "The problem is that even though the ordinary training process is only looking at predictions on the training data when it learns values for the weight parameters, the same is not true of us. We, as modelers, are evaluating the model by looking at predictions on the validation data when we decide to explore new hyperparameter values! So subsequent versions of the model are, indirectly, shaped by us having seen the validation data. Just as the automatic training process is in danger of overfitting the training data, we are in danger of overfitting the validation data through human trial and error and exploration.\n",
        "\n",
        "The solution to this conundrum is to introduce another level of even more highly reserved data, the *test set*. Just as we hold back the validation data from the training process, we must hold back the test set data even from ourselves. It cannot be used to improve the model; it can only be used to evaluate the model at the very end of our efforts. In effect, we define a hierarchy of cuts of our data, based on how fully we want to hide it from training and modeling processes: training data is fully exposed, the validation data is less exposed, and test data is totally hidden. This hierarchy parallels the different kinds of modeling and evaluation processes themselves—the automatic training process with back propagation, the more manual process of trying different hyper-parameters between training sessions, and the assessment of our final result.\n",
        "\n",
        "The test and validation sets should have enough data to ensure that you get a good estimate of your accuracy. If you're creating a cat detector, for instance, you generally want at least 30 cats in your validation set. That means that if you have a dataset with thousands of items, using the default 20% validation set size may be more than you need. On the other hand, if you have lots of data, using some of it for validation probably doesn't have any downsides.\n",
        "\n",
        "Having two levels of \"reserved data\"—a validation set and a test set, with one level representing data that you are virtually hiding from yourself—may seem a bit extreme. But the reason it is often necessary is because models tend to gravitate toward the simplest way to do good predictions (memorization), and we as fallible humans tend to gravitate toward fooling ourselves about how well our models are performing. The discipline of the test set helps us keep ourselves intellectually honest. That doesn't mean we *always* need a separate test set—if you have very little data, you may need to just have a validation set—but generally it's best to use one if at all possible.\n",
        "\n",
        "This same discipline can be critical if you intend to hire a third party to perform modeling work on your behalf. A third party might not understand your requirements accurately, or their incentives might even encourage them to misunderstand them. A good test set can greatly mitigate these risks and let you evaluate whether their work solves your actual problem.\n",
        "\n",
        "To put it bluntly, if you're a senior decision maker in your organization (or you're advising senior decision makers), the most important takeaway is this: if you ensure that you really understand what test and validation sets are and why they're important, then you'll avoid the single biggest source of failures we've seen when organizations decide to use AI. For instance, if you're considering bringing in an external vendor or service, make sure that you hold out some test data that the vendor *never gets to see*. Then *you* check their model on your test data, using a metric that *you* choose based on what actually matters to you in practice, and *you* decide what level of performance is adequate. (It's also a good idea for you to try out some simple baseline yourself, so you know what a really simple model can achieve. Often it'll turn out that your simple model performs just as well as one produced by an external \"expert\"!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlKp-tY6VryK"
      },
      "source": [
        "### Use Judgment in Defining Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxjMV8mAVryK"
      },
      "source": [
        "To do a good job of defining a validation set (and possibly a test set), you will sometimes want to do more than just randomly grab a fraction of your original dataset. Remember: a key property of the validation and test sets is that they must be representative of the new data you will see in the future. This may sound like an impossible order! By definition, you haven’t seen this data yet. But you usually still do know some things.\n",
        "\n",
        "It's instructive to look at a few example cases. Many of these examples come from predictive modeling competitions on the [Kaggle](https://www.kaggle.com/) platform, which is a good representation of problems and methods you might see in practice.\n",
        "\n",
        "One case might be if you are looking at time series data. For a time series, choosing a random subset of the data will be both too easy (you can look at the data both before and after the dates you are trying to predict) and not representative of most business use cases (where you are using historical data to build a model for use in the future). If your data includes the date and you are building a model to use in the future, you will want to choose a continuous section with the latest dates as your validation set (for instance, the last two weeks or last month of available data).\n",
        "\n",
        "Suppose you want to split the time series data in <<timeseries1>> into training and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHqKh4VJVryK"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/timeseries1.png?raw=1\" width=\"400\" id=\"timeseries1\" caption=\"A time series\" alt=\"A serie of values\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bZAwf01VryK"
      },
      "source": [
        "A random subset is a poor choice (too easy to fill in the gaps, and not indicative of what you'll need in production), as we can see in <<timeseries2>>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kE926hUVryK"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/timeseries2.png?raw=1\" width=\"400\" id=\"timeseries2\" caption=\"A poor training subset\" alt=\"Random training subset\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPIHpZ-VryK"
      },
      "source": [
        "Instead, use the earlier data as your training set (and the later data for the validation set), as shown in <<timeseries3>>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZuE0E4eVryK"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/timeseries3.png?raw=1\" width=\"400\" id=\"timeseries3\" caption=\"A good training subset\" alt=\"Training subset using the data up to a certain timestamp\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMz-UQ5lVryL"
      },
      "source": [
        "For example, Kaggle had a competition to [predict the sales in a chain of Ecuadorian grocery stores](https://www.kaggle.com/c/favorita-grocery-sales-forecasting). Kaggle's training data ran from Jan 1 2013 to Aug 15 2017, and the test data spanned Aug 16 2017 to Aug 31 2017. That way, the competition organizer ensured that entrants were making predictions for a time period that was *in the future*, from the perspective of their model. This is similar to the way quant hedge fund traders do *back-testing* to check whether their models are predictive of future periods, based on past data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxyPJTkVryL"
      },
      "source": [
        "A second common case is when you can easily anticipate ways the data you will be making predictions for in production may be *qualitatively different* from the data you have to train your model with.\n",
        "\n",
        "In the Kaggle [distracted driver competition](https://www.kaggle.com/c/state-farm-distracted-driver-detection), the independent variables are pictures of drivers at the wheel of a car, and the dependent variables are categories such as texting, eating, or safely looking ahead. Lots of pictures are of the same drivers in different positions, as we can see in <<img_driver>>. If you were an insurance company building a model from this data, note that you would be most interested in how the model performs on drivers it hasn't seen before (since you would likely have training data only for a small group of people). In recognition of this, the test data for the competition consists of images of people that don't appear in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUsfQm_5VryL"
      },
      "source": [
        "<img src=\"https://github.com/fastai/fastbook/blob/master/images/driver.PNG?raw=1\" width=\"600\" id=\"img_driver\" caption=\"Two pictures from the training data\" alt=\"Two pictures from the training data, showing the same driver\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EK3Qj8RVryL"
      },
      "source": [
        "If you put one of the images in <<img_driver>> in your training set and one in the validation set, your model will have an easy time making a prediction for the one in the validation set, so it will seem to be performing better than it would on new people. Another perspective is that if you used all the people in training your model, your model might be overfitting to particularities of those specific people, and not just learning the states (texting, eating, etc.).\n",
        "\n",
        "A similar dynamic was at work in the [Kaggle fisheries competition](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring) to identify the species of fish caught by fishing boats in order to reduce illegal fishing of endangered populations.  The test set consisted of boats that didn't appear in the training data.  This means that you'd want your validation set to include boats that are not in the training set.\n",
        "\n",
        "Sometimes it may not be clear how your validation data will differ.  For instance, for a problem using satellite imagery, you'd need to gather more information on whether the training set just contained certain geographic locations, or if it came from geographically scattered data."
      ]
    }
  ]
}